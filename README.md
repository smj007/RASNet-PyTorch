<div align="center">

<samp>
     
# RASNet: Segmentation for Tracking Surgical Instruments in Surgical Videos Using Refined Attention Segmentation Network ([arXiv](https://arxiv.org/abs/1905.08663))
     
**NOTE - Unofficial PyTorch implementation of RASNet**
  
---
  
  </div>  
     
</samp>

### Sample Data

Download from **[[`Dataset Link`](https://drive.google.com/file/d/1OwWfgBZE0W5grXVaQN63VUUaTvufEmW0/view?usp=sharing)]** and place it inside the repository root and unzip. To train the model, download the Endovis 17/18 dataset from [here](https://endovis.grand-challenge.org/) and set the root directory in **main.py**

### Usage (Training and Validation)

```bash
python3 main.py    
```

### Dependencies
     
This code was developed with ```python3.6```
```
Python (3.6.x)
PyTorch (1.7.x)
CUDA (10.2)
cuDNN (7.6.5)
numpy (1.19.5)     
```
For further details, contact **Sai Mitheran** via [Linkedin](https://www.linkedin.com/in/sai-mitheran-4b9422187/), or via email by clicking the icon below.  

<a href="mailto:saimitheran06@gmail.com?"><img src="https://img.shields.io/badge/gmail-%23DD0031.svg?&style=for-the-badge&logo=gmail&logoColor=white"/></a>     
     
  </samp>  
  
  </div>  
   
---  

### To cite the original paper     

```bibtex
@misc{ni2019rasnet,
      title={RASNet: Segmentation for Tracking Surgical Instruments in Surgical Videos Using Refined Attention Segmentation Network}, 
      author={Zhen-Liang Ni and Gui-Bin Bian and Xiao-Liang Xie and Zeng-Guang Hou and Xiao-Hu Zhou and Yan-Jie Zhou},
      year={2019},
      eprint={1905.08663},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```

---


